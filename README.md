# Spark-Optimization-Tutorial
Apache Spark is a fast and general-purpose cluster computing system. On current moment Apache Spark is of the most popular technologies for big data processing. Despite Apache Spark can process large amount of data, it can take a long time. In the modern world nobody likes to wait for a result and even such technology as Apache Spark needs to be optimized. Often developers don’t pay enough attention to Apache Spark optimization. This report doesn’t cover all Apache Spark optimization techniques but the main of this will be described. This report should help users to decrease wasted time. 

Apache Spark consists of the following components:
- Core
- SQL
- Streaming
- MLib
- GraphX

Two component will be compared in this report. It’s Spark Core and Spark SQL. Spark SQL can be divided into two parts: DataFrame and pure Spark SQL. In spite of DataFrame and pure Spark SQL are the same under the hood, they will also take part in comparison. 
